<!DOCTYPE html>
<html>

<head>
    <title>Extracting parameter estimates</title>
    <style>
        body {
            max-width: 800px;
            margin: 0 auto; /* Center the content horizontally */
            padding: 20px; /* Optional padding for better readability */
        }
        .link-container {
            display: flex;
            justify-content: space-between;
        }
    
        .left-link {
            margin-right: auto;
        }

        .responsive-image {
            max-width: 800px; 
            height: auto; /* Maintain the aspect ratio */
          }
    </style>
</head>

<body>
    <h1>Extracting parameter estimates</h1>
    
    <p> When it comes to extracting parameter estimates, I recommed using binary ROI mask in a .nii format. These can be easily translated into logical matrices in MATLAB. 
        Althogh the code below should be fairly straightforward, I provide a simple explanation on how it works:
    </p>

    <ul>
        <li>Locate and load the binary masks which you created during the previous step; use the function niftiread() <br>
            [Note that you need access to the Image processing toolbox in MATLAB. UT Dallas has a license, and it should be a part of your MATLAB installation. If it is not, email cvltech@utdallas.edu.
            spm_read_vols(spm_vol(nii_file)) works as well, but niftiread is MUCH faster]. <br>
            The logical() argument will convert the binary matrix such that each voxel is labeled as TRUE/FALSE. All voxels that exist in the ROI are 1 = "TRUE".</li>
        <li>Specify and load subject files such as the mat file which contains all paths to the subject's trialwise betas. In the example below, the mat file will load the variable "study_data".</li>
        <li>Loop through all trials, load the beta .nii file for each trial with niftiread() as you go.</li>
        <li>Once the beta for a given trial is loaded as a matrix, loop through ROIs and use the logical matrix corresponding with each ROI to select only those voxels that were labeled 1 / TRUE, 
            [beta_map(curMask);] <br>
            You should save the output in your mat file as a new structure (I call mine extracted_data). This field will be used in your PSA analyses and it contains the betas of all voxels in your ROI.<br>
            You may also save the across-voxel mean beta value, you can use this value in univariate analyses.</li>
        <li>Finish going through trials and subjects, save the subject's mat file as you go.</li>
    </ul>

    <script src="https://gist.github.com/SabinaSrokova/29355f3d4b609e941304c4e200160660.js"></script>

    <h2>Times when a group mask may be necessary</h2>
    <p> 
        As you may notice in the code above, you may sometimes need to apply a group level mask when loading your ROI file. This may be the case when:
    </p>
    <ul>
        <li><strong>You modeled your LSA with unsmoothed data.</strong>
            Because unsmoothed data has A LOT of dropout, it is basically guaranteed that you will end up trying to load voxels that do not exist in your subject's beta file 
            (this is easy to catch because even a single missing voxel will result in a "NaN" mean beta). The dropout will vary from subject to subject, and although you can "catch" these voxels in each subject and remove them as needed,
            I definitely do not recommend removing them on a single suject basis. For example, older adults may have a lot more dropout than younger adults, which means that your ROIs in older adults would end up smaller than in younger adults.
            I like to ensure I keep the same voxels in everyone, which is when an unsmoothed group mask is necessary. Unfortunately, LSA will generate binary masks only for each individual subject, so creating an unsmoothed 
            group mask will be on you. You can use SPM's imcalc to combine all masks to generate a file that contains only those voxels that exist in every single subject (using the & operator).
            Alternatively, you can edit one of my old scripts I share below. 
        </li>
        <li>
            <strong>Your data is smoothed, but the ROI came from a different dataset.</strong>
            Signal dropout differs between experiments. Luckily, if you have also modeled your data with the standard 1st to 2nd level mass-univariate GLM approach,
            you can simply use a group mask that was generated during the 2nd level step (assuming you used smoothed data on the mass-univariate analysis...). 
        </li>
    </ul>
    <script src="https://gist.github.com/SabinaSrokova/209da74cf0267bbe713bddaaaabaa16f.js"></script>

    <p>
        A comparision between an unsmoothed vs smoothed group mask is illustrated below. It is also important to be mindful of *where* your dropout occurs. For example, in this study, 
        you would have a hard time extracting group-level data from the striatum ... 
        This is unfortunately typical and unavoidable in aging studies (iron deposition leading to signal loss). It is just something to be aware of.
        Luckily, this does not mean that all older adults are missing these voxels. More likely, it is just one or two of your subjects. If your region of interest ends up being
        in the striatum, you will need to identify and exclude these few older adults and recreate your group mask without them.
    </p>

    <img src="https://raw.githubusercontent.com/SabinaSrokova/SabinaSrokova.github.io/main/examples/group%20mask.PNG" alt="Group mask comparison" class="responsive-image">


    <div class="link-container">
        <a class="left-link" href="https://sabinasrokova.github.io/">Return to Menu</a>
        <a href="univariate.html">Continue to: Univariate analysis</a>
    </div>
</body>

</html>